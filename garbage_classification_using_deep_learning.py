# -*- coding: utf-8 -*-
"""GARBAGE CLASSIFICATION USING DEEP LEARNING

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11esqH1EdzcF-6szAQTl67sjW5-Ek_ESA

**PROBLEM STATEMENT :** The present way of separating waste/garbage is the hand-picking method, whereby someone is employed to separate out the different objects/materials. The person who separates waste, is prone to diseases due to the harmful substances in the garbage. With this in mind, it motivated us to develop an automated system which is able to sort the waste. and this system can take a short time to sort the waste, and it will be more accurate in sorting than the manual way. With the system in place, the beneficial separated waste can still be recycled and converted to energy and fuel for the growth of the economy. The system that is developed for the separation of the accumulated waste is based on the combination of Convolutional Neural Network.

**Load Dataseet**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**DATA Augumentation**"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255,
                                   zoom_range=0.1,
                                   shear_range=0.1,
                                   horizontal_flip=True,
                                   vertical_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

"""**Insert Train Dataset and Test Dataset**"""

train_transform = train_datagen.flow_from_directory('/content/drive/MyDrive/Garbage classification/train',
                                           target_size=(128,128),
                                           class_mode='categorical',
                                           batch_size=64)

test_transform = test_datagen.flow_from_directory('/content/drive/MyDrive/Garbage classification/test',
                                         target_size=(128,128),
                                         class_mode='categorical',
                                         batch_size=64)

"""**Importing Libraries**"""

#to define linear initializations import Sequential
from tensorflow.keras.models import Sequential
#to add layers import Dense
from tensorflow.keras.layers import Dense
#to create a convolution kernel import Convolution2D
from tensorflow.keras.layers import Convolution2D
#Adding Max Pooling Layer
from tensorflow.keras.layers import MaxPooling2D
#Adding Flatten Layer
from tensorflow.keras.layers import Flatten
from tensorflow.keras.optimizers import Adam

#Initialize The Model
model=Sequential()

"""**Adding CNN layer**"""

#first Convolution layer and pooling
model.add(Convolution2D(32,(3,3),input_shape=(128,128,3), activation='relu'))
model.add(MaxPooling2D(2,2))

#Second Convolution layer and pooling
model.add(Convolution2D(64,(3,3),padding='same',activation='relu'))
#input shape is going to be the pooled feature maps from the previous convolution.
model.add(MaxPooling2D(pool_size=2))

#Third Convolution layer and pooling
model.add(Convolution2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(2,2))

#fourth Convolution layer and pooling
model.add(Convolution2D(32,(3,3),padding='same',activation='relu'))
#input shape is going to be the pooled feature maps from the previous convolution.
model.add(MaxPooling2D(pool_size=2))

#Flattering Layers
model.add(Flatten())

"""**Adding Fully Connected Layer**"""

#Adding 1st hidden layer
model.add(Dense(kernel_initializer='uniform',activation='relu',units=200))
#Adding 2nd hidden layer
model.add(Dense(kernel_initializer='uniform',activation='relu',units=100))
model.add(Dense(kernel_initializer='uniform',activation='softmax',units=6))

"""**Model Summary**"""

model.summary()

"""**Compile a model**"""

model.compile(loss='categorical_crossentropy',optimizer='adam',
              metrics=['accuracy'])

"""# **Model Training**"""

res=model.fit(train_transform,steps_per_epoch=2527//64,validation_steps=1328//64,
              epochs=100,validation_data=test_transform)

"""**Save The Model**"""

model.save('Garbage1.h5')

"""**Model Testing**"""

#import numpy library
import numpy as np
#import load_model methood to load our saved model
from tensorflow.keras.models import load_model
#import image from keras.preprocessing
from tensorflow.keras.preprocessing import image
model=load_model('Garbage1.h5')

img=image.load_img('/content/drive/MyDrive/Garbage classification/train/trash/trash99.jpg',
                   target_size=(128,128))
x=image.img_to_array(img)
x=np.expand_dims(x,axis=0)

a=np.argmax(model.predict(x),axis=1)

index=['0','1','2','3','4','5']
result=str(index[a[0]])
result

train_transform.class_indices

index1=['cardboard','glass','metal','paper','plastic','trash']
result1=str(index1[a[0]])
result1